{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIPL0tHtdKEf"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcwE4-_MlyQ_",
        "outputId": "580be2af-ba38-4f5b-d379-453dbaf1105b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epwZm8mMlIZr"
      },
      "outputs": [],
      "source": [
        "#importing dataset through kaggle API\n",
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "  \"https://www.kaggle.com/datasets/anlgrbz/student-demographics-online-education-dataoulad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNUWay1ifR4Q"
      },
      "outputs": [],
      "source": [
        "#putting the csv files into dataframes\n",
        "studentInfo = pd.read_csv('/content/student-demographics-online-education-dataoulad/studentInfo.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n",
        "#adding column 'index' to dataframe studentInfo\n",
        "studentInfo['Index'] = range(1, len(studentInfo) + 1)\n",
        "#studentInfo\n",
        "\n",
        "\n",
        "studentAssessment = pd.read_csv('/content/student-demographics-online-education-dataoulad/studentAssessment.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n",
        "courses = pd.read_csv('/content/student-demographics-online-education-dataoulad/courses.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n",
        "assessments = pd.read_csv('/content/student-demographics-online-education-dataoulad/assessments.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n",
        "studentRegistration = pd.read_csv('/content/student-demographics-online-education-dataoulad/studentRegistration.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n",
        "studentVle = pd.read_csv('/content/student-demographics-online-education-dataoulad/studentVle.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n",
        "vle = pd.read_csv('/content/student-demographics-online-education-dataoulad/vle.csv', \\\n",
        "                           sep=',', encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFb3bnD79qtM"
      },
      "outputs": [],
      "source": [
        "studentVle.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCll19_txCvp"
      },
      "outputs": [],
      "source": [
        "studentAssessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFvUiAXFVCIh"
      },
      "outputs": [],
      "source": [
        "studentRegistration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk-TrOlNkChU"
      },
      "outputs": [],
      "source": [
        "courses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYe6fr4okDqP"
      },
      "outputs": [],
      "source": [
        "assessments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmwLNpe6HiV-"
      },
      "outputs": [],
      "source": [
        "assessments[assessments[\"code_module\"] == \"AAA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCqVncONkGQv"
      },
      "outputs": [],
      "source": [
        "vle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwXbXtKerjYB"
      },
      "outputs": [],
      "source": [
        "vle['week_to'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPVDo73cotSl"
      },
      "outputs": [],
      "source": [
        "#vle[vle['week_to'] == 'NaN']\n",
        "vle['week_to'] = vle['week_to'].astype(str).str.strip()\n",
        "vle['week_from'] = vle['week_from'].astype(str).str.strip()\n",
        "\n",
        "\n",
        "heyy = vle[vle['week_to'] != 'nan']\n",
        "heyy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kefI2tZ7v2ij"
      },
      "outputs": [],
      "source": [
        "vle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAAiBdO5wgce"
      },
      "source": [
        "* Only 1121 instances out of a total of 6364 have non-null values. Dataframe cannot be used for feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwvXf-sTbWmB"
      },
      "outputs": [],
      "source": [
        "vle[vle['code_module'] == 'AAA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svgMPYj3yGo7"
      },
      "outputs": [],
      "source": [
        "studentInfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2bF4zVA1vx0"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb-c5RrvkHmq"
      },
      "outputs": [],
      "source": [
        "#number of students registered\n",
        "len(studentInfo['id_student'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc6n412_1zBx"
      },
      "outputs": [],
      "source": [
        "#number of presentations per module\n",
        "courses['code_module'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faE3N9tXaX8Q"
      },
      "outputs": [],
      "source": [
        "#number of assessments per presentation \n",
        "assessments['code_module'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPBE3PeLZwro"
      },
      "outputs": [],
      "source": [
        "#different categoric variables\n",
        "studentInfo['imd_band'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KniXsxXH2Ih2"
      },
      "outputs": [],
      "source": [
        "studentInfo[studentInfo['id_student'] == 584077]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y_076GscCIE"
      },
      "outputs": [],
      "source": [
        "print('Number of missing entries per column:')\n",
        "studentInfo.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYnpDsTzRLFs"
      },
      "source": [
        "* 1111 instances of imd_band missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-S7nEQ8Wurv"
      },
      "outputs": [],
      "source": [
        "# plot the density graph\n",
        "studentRegistration['date_registration'].plot(kind='density')\n",
        "#plt.xlim(0,400)\n",
        "plt.xlabel('student_registration')\n",
        "plt.ylabel('density')\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI4UUHFsVYLl"
      },
      "outputs": [],
      "source": [
        "# plot the density graph\n",
        "studentInfo['studied_credits'].plot(kind='density')\n",
        "plt.xlim(0,400)\n",
        "plt.xlabel('studied_credits')\n",
        "plt.ylabel('density')\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRS5K8K-5-8i"
      },
      "outputs": [],
      "source": [
        "#plot numbers of students each course module\n",
        "modulo = studentInfo.groupby('code_module').agg({'id_student':'count'}).reset_index().\\\n",
        "    rename(columns={\"code_module\": \"code_module\", 'id_student': 'id_student'})\n",
        "\n",
        "modulo['Percentual'] = modulo.apply(lambda x: round(100 * (x['id_student'] / modulo['id_student'].sum()),2), axis=1)\n",
        "    \n",
        "fig = px.bar(modulo, x='code_module', y='id_student', \\\n",
        "    text='Percentual', color='code_module',  hover_data=['id_student'],\\\n",
        "        template=\"seaborn\")\n",
        "\n",
        "fig.update_layout(\n",
        "    margin=dict(l=20, r=50, t=50, b=20),\n",
        "    title = 'Distribution - Coursed Module',\n",
        "    #xaxis_title=\"Module completed\",\n",
        "    yaxis_title=\"Number of students\",\n",
        "    legend_title=\"Module completed\",\n",
        "    width=600, \n",
        "    height=400,\n",
        "    uniformtext_minsize=10, \n",
        "    uniformtext_mode='hide',\n",
        ")\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcv4SC9vDscJ"
      },
      "outputs": [],
      "source": [
        "df = studentInfo.groupby(['code_module', 'final_result']).agg({'id_student':'count'}).reset_index()\n",
        "\n",
        "\n",
        "df['percentage'] = df.apply(lambda x:  round(100 * (x['id_student'] / df[df['final_result'] == x['final_result']]['id_student'].sum()),2), axis=1)\n",
        "\n",
        "fig = px.bar(df, x=\"final_result\", y=\"percentage\", text=\"percentage\", color=\"code_module\",\n",
        "            hover_data=['percentage'], barmode = 'stack', template=\"seaborn\")\n",
        "\n",
        "fig.update_layout(\n",
        "    margin=dict(l=20, r=50, t=50, b=20),\n",
        "    title = 'Results per Module Attended',\n",
        "    xaxis_title=\"final_result\",\n",
        "    yaxis_title=\"percentage [%]\",\n",
        "    legend_title=\"Module Attended\",\n",
        "    width=700, \n",
        "    height=500,\n",
        "    uniformtext_minsize=9, \n",
        "    uniformtext_mode='hide',\n",
        ")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKBZaQ687YvE"
      },
      "source": [
        "* The above disparity can be explained by the uneven sampling of the number of students registered for each module(for all semesters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx1kwOW-E2QN"
      },
      "outputs": [],
      "source": [
        "code_presentation = studentInfo.groupby('code_presentation').agg({'id_student':'count'}).reset_index()\n",
        "\n",
        "code_presentation['percentage'] = code_presentation.apply(lambda x: round(100 * (x['id_student'] / code_presentation['id_student'].sum()),2), axis=1)\n",
        "    \n",
        "fig = px.bar(code_presentation, x='code_presentation', y='id_student', \\\n",
        "    text='percentage', color='code_presentation',  hover_data=['id_student'],\\\n",
        "        template=\"seaborn\")\n",
        "\n",
        "fig.update_layout(\n",
        "    margin=dict(l=20, r=50, t=50, b=20),\n",
        "    title = 'Distribution - Period Attended',\n",
        "    xaxis_title=\"period studied\",\n",
        "    yaxis_title=\"Quantity [Students]\",\n",
        "    legend_title=\"Period Attended\",\n",
        "    width=600, \n",
        "    height=400,\n",
        "    uniformtext_minsize=10, \n",
        "    uniformtext_mode='hide',\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIIBjjoDHfNr"
      },
      "outputs": [],
      "source": [
        "region = studentInfo[['region', 'id_student']].drop_duplicates().groupby('region').agg({'id_student':'count'}).reset_index()\n",
        "\n",
        "\n",
        "region['percentage'] = region.apply(lambda x: round(100 * (x['id_student'] / region['id_student'].sum()), 2) ,axis=1)\n",
        "\n",
        "fig = px.bar(region, x='region', y='id_student', text='percentage', color ='region',  template=\"seaborn\")\n",
        "\n",
        "fig.update_layout(\n",
        "    margin=dict(l=20, r=50, t=50, b=20),\n",
        "    title = 'Distribution - Location',\n",
        "    xaxis_title=\"Region\",\n",
        "    yaxis_title=\"Quantity [Students]\",\n",
        "    showlegend=False,\n",
        "    width=800, \n",
        "    height=550,\n",
        "    uniformtext_minsize=10, \n",
        "    uniformtext_mode='hide',\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq1qRo7NgH8q"
      },
      "source": [
        "###Skewness of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4CW2qEDcLaO"
      },
      "outputs": [],
      "source": [
        "#hello = dict(studentInfo['final_result'].value_counts())\n",
        "skew = studentInfo['final_result'].value_counts().to_dict()\n",
        "skew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOuPTiHYcti5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create a bar plot\n",
        "plt.bar(skew.keys(), skew.values())\n",
        "\n",
        "# set axis labels and title\n",
        "plt.xlabel('result')\n",
        "plt.ylabel('count')\n",
        "plt.title('skewness')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ILmEBe0YvLI"
      },
      "source": [
        "### The data distribution on the basis of the labels is as follows:\n",
        "pass - 37.9%, withdrawn - 31.1%, fail - 21.6%, distinction - 9.2%\n",
        "\n",
        "Hence, data is heavily skewed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6PZN4WbgTv7"
      },
      "outputs": [],
      "source": [
        "#vle['week_from'].value_counts()\n",
        "print(vle['week_from'].isnull().sum())\n",
        "print(vle['week_to'].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L2Kvav6yt0M"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Fl34QO4Uwk"
      },
      "source": [
        "## plot between gender and target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoMQ1q7EnNNm"
      },
      "outputs": [],
      "source": [
        "male_pass = studentInfo[(studentInfo['gender'] == 'M') & (studentInfo['final_result'] == 'Pass')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "female_pass = studentInfo[(studentInfo['gender'] == 'F') & (studentInfo['final_result'] == 'Pass')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "gender_pass_combined = pd.concat([male_pass, female_pass], ignore_index=True)\n",
        "\n",
        "male_fail = studentInfo[(studentInfo['gender'] == 'M') & (studentInfo['final_result'] == 'Fail')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "female_fail = studentInfo[(studentInfo['gender'] == 'F') & (studentInfo['final_result'] == 'Fail')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "gender_fail_combined = pd.concat([male_fail, female_fail], ignore_index=True)\n",
        "\n",
        "male_distinction = studentInfo[(studentInfo['gender'] == 'M') & (studentInfo['final_result'] == 'Distinction')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "female_distinction = studentInfo[(studentInfo['gender'] == 'F') & (studentInfo['final_result'] == 'Distinction')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "gender_distinction_combined = pd.concat([male_distinction, female_distinction], ignore_index=True)\n",
        "\n",
        "male_withdrawn = studentInfo[(studentInfo['gender'] == 'M') & (studentInfo['final_result'] == 'Withdrawn')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "female_withdrawn = studentInfo[(studentInfo['gender'] == 'F') & (studentInfo['final_result'] == 'Withdrawn')].groupby(['gender', 'final_result']).size().reset_index(name='Count')\n",
        "gender_withdrawn_combined = pd.concat([male_withdrawn, female_withdrawn], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvZwPhGa54Ve"
      },
      "outputs": [],
      "source": [
        "gender_combined = pd.concat([gender_pass_combined, gender_fail_combined, gender_distinction_combined, gender_withdrawn_combined], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui_EfjDC8mPO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create some data for the plots\n",
        "x = ['Pass', 'Fail', 'Distinction', 'Withdrawn']\n",
        "y1 = gender_combined.loc[gender_combined['gender'] == 'M', 'Count'].tolist()\n",
        "y2 = gender_combined.loc[gender_combined['gender'] == 'F', 'Count'].tolist()\n",
        "\n",
        "#normalising with total population count for that gender\n",
        "y1 = [i / 17875*100 for i in y1]\n",
        "y2 = [i/14718*100 for i in y2]\n",
        "\n",
        "X_axis = np.arange(len(x))\n",
        "\n",
        "plt.bar(X_axis - 0.2, y1, 0.4, label = 'Male')\n",
        "plt.bar(X_axis + 0.2, y2, 0.4, label = 'Female')\n",
        "\n",
        "plt.xticks(X_axis, x)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"ratio of people\")\n",
        "plt.title(\"Gender v proportion\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N-NHZDzWqES"
      },
      "source": [
        "### no disparity/trend between the two genders. Irrelevant feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUj4AyLP2OOT"
      },
      "source": [
        "# plot between number of previous attempts and target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30l8yr8k2TW_"
      },
      "outputs": [],
      "source": [
        "pass0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass1 = studentInfo[(studentInfo['num_of_prev_attempts'] >= 1) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "\n",
        "attempt_pass_combined = pd.concat([pass0, pass1], ignore_index=True)\n",
        "\n",
        "fail0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail1 = studentInfo[(studentInfo['num_of_prev_attempts'] >= 1) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "attempt_fail_combined = pd.concat([fail0, fail1], ignore_index=True)\n",
        "\n",
        "distinction0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction1 = studentInfo[(studentInfo['num_of_prev_attempts'] >= 1) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "attempt_distinction_combined = pd.concat([distinction0, distinction1], ignore_index=True)\n",
        "\n",
        "withdrawn0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn1 = studentInfo[(studentInfo['num_of_prev_attempts'] >= 1) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "attempt_withdrawn_combined = pd.concat([withdrawn0, withdrawn1], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5QyWdwk2mmg"
      },
      "outputs": [],
      "source": [
        "attempts_combined = pd.concat([attempt_pass_combined, attempt_fail_combined, attempt_distinction_combined, attempt_withdrawn_combined], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e82H76Ni2mlH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create some data for the plots\n",
        "x = ['Pass', 'Fail', 'Distinction', 'Withdrawn']\n",
        "#y1 = attempts_combined.loc[attempts_combined['num_of_prev_attempts'] == 0, 'Count'].tolist()\n",
        "#y2 = attempts_combined.loc[attempts_combined['num_of_prev_attempts'] == 1, 'Count'].tolist()\n",
        "y1 = []\n",
        "y2 = []\n",
        "for index, row in attempts_combined.iloc[::2].iterrows():\n",
        "    # convert the value in the column of the current row\n",
        "    converted_value = row['Count'] \n",
        "    \n",
        "    # append the converted value to the list\n",
        "    y1.append(converted_value)\n",
        "\n",
        "for index, row in attempts_combined.iloc[1::2].iterrows():\n",
        "    # convert the value in the column of the current row\n",
        "    converted_value = row['Count'] \n",
        "    \n",
        "    # append the converted value to the list\n",
        "    y2.append(converted_value)\n",
        "\n",
        "#normalising with total population count for that gender\n",
        "y1 = [i /28421*100 for i in y1]\n",
        "y2 = [i/4172*100 for i in y2]\n",
        "\n",
        "X_axis = np.arange(len(x))\n",
        "print(len(X_axis))\n",
        "print(len(y1))\n",
        "plt.bar(X_axis - 0.2, y1, 0.4, label = '0 previous attempts')\n",
        "plt.bar(X_axis + 0.2, y2, 0.4, label = '1 or more previous attempts')\n",
        "\n",
        "plt.xticks(X_axis, x)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"% of people\")\n",
        "plt.title(\"Gender v proportion\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE1r-44IWFAa"
      },
      "source": [
        "### 30% of the students who had re-registered for any course 1 or more than once failed the semester. 35% of the students who had re-registered for any course 1 or more than once too have failed the semester.\n",
        "\n",
        "### Can be a relevant feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z16UnPBdZbVj"
      },
      "source": [
        "## same ting but with all 7 possible values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KznKxtjWESG"
      },
      "outputs": [],
      "source": [
        "pass0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass1 = studentInfo[(studentInfo['num_of_prev_attempts'] == 1) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass2 = studentInfo[(studentInfo['num_of_prev_attempts'] == 2) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass3 = studentInfo[(studentInfo['num_of_prev_attempts'] == 3) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass4 = studentInfo[(studentInfo['num_of_prev_attempts'] == 4) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass5 = studentInfo[(studentInfo['num_of_prev_attempts'] == 5) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "pass6 = studentInfo[(studentInfo['num_of_prev_attempts'] == 6) & (studentInfo['final_result'] == 'Pass')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "\n",
        "attempt_pass_combined = pd.concat([pass0, pass1,pass2,pass3,pass4,pass5,pass6], ignore_index=True)\n",
        "\n",
        "fail0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail1 = studentInfo[(studentInfo['num_of_prev_attempts'] == 1) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail2 = studentInfo[(studentInfo['num_of_prev_attempts'] == 2) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail3 = studentInfo[(studentInfo['num_of_prev_attempts'] == 3) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail4 = studentInfo[(studentInfo['num_of_prev_attempts'] == 4) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail5 = studentInfo[(studentInfo['num_of_prev_attempts'] == 5) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "fail6 = studentInfo[(studentInfo['num_of_prev_attempts'] == 6) & (studentInfo['final_result'] == 'Fail')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "\n",
        "attempt_fail_combined = pd.concat([fail0, fail1,fail2,fail3,fail4,fail5,fail6], ignore_index=True)\n",
        "\n",
        "distinction0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction1 = studentInfo[(studentInfo['num_of_prev_attempts'] == 1) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction2 = studentInfo[(studentInfo['num_of_prev_attempts'] == 2) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction3 = studentInfo[(studentInfo['num_of_prev_attempts'] == 3) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction4 = studentInfo[(studentInfo['num_of_prev_attempts'] == 4) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction5 = studentInfo[(studentInfo['num_of_prev_attempts'] == 5) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "distinction6 = studentInfo[(studentInfo['num_of_prev_attempts'] == 6) & (studentInfo['final_result'] == 'Distinction')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "\n",
        "attempt_distinction_combined = pd.concat([distinction0, distinction1,distinction2,distinction3,distinction4,distinction5,distinction6], ignore_index=True)\n",
        "\n",
        "withdrawn0 = studentInfo[(studentInfo['num_of_prev_attempts'] == 0) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn1 = studentInfo[(studentInfo['num_of_prev_attempts'] == 1) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn2 = studentInfo[(studentInfo['num_of_prev_attempts'] == 2) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn3 = studentInfo[(studentInfo['num_of_prev_attempts'] == 3) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn4 = studentInfo[(studentInfo['num_of_prev_attempts'] == 4) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn5 = studentInfo[(studentInfo['num_of_prev_attempts'] == 5) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "withdrawn6 = studentInfo[(studentInfo['num_of_prev_attempts'] == 6) & (studentInfo['final_result'] == 'Withdrawn')].groupby(['final_result']).size().reset_index(name='Count')\n",
        "\n",
        "attempt_withdrawn_combined = pd.concat([withdrawn0, withdrawn1,withdrawn2,withdrawn3,withdrawn4,withdrawn5,withdrawn6], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yPnuUuFgcw_"
      },
      "outputs": [],
      "source": [
        "attempts_combined_new = pd.concat([attempt_pass_combined, attempt_fail_combined, attempt_distinction_combined, attempt_withdrawn_combined], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_mSMb6Utngl"
      },
      "outputs": [],
      "source": [
        "new_row = {'final_result': 'Misc', 'Count': 0}\n",
        "\n",
        "# append the new row to the dataframe\n",
        "attempts_combined_new = attempts_combined_new.append(new_row, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN0L8XZJJKm4"
      },
      "outputs": [],
      "source": [
        "attempts_combined_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd4sD8iHaHUM"
      },
      "source": [
        "#Imd_band v target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T6p8NYWxmux"
      },
      "outputs": [],
      "source": [
        "imd_band = studentInfo.groupby(['imd_band', 'final_result']).agg(count=('Index','count')).reset_index()\n",
        "imd_band = imd_band.sort_values(['final_result', 'imd_band'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnnWvaqv1Rtw"
      },
      "outputs": [],
      "source": [
        "grouped = imd_band.groupby(['final_result'])['count'].transform('sum')\n",
        "\n",
        "# divide the count values in the original dataframe by the corresponding group sum\n",
        "imd_band['count_normalized'] = imd_band['count'] / grouped\n",
        "imd_band"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9XUEXi29Gg"
      },
      "source": [
        "\n",
        "*   Around 60% students that failed belong to the imd_band 0-60%(collective of 6 imd groups)\n",
        "\n",
        "*   Around 50% students that withdrew belong to the imd_band 0-50%(collective of 5 imd groups)\n",
        "\n",
        "* Patterns seem promising. Can be used as a feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swgy5l0OB6P5"
      },
      "source": [
        "#Age_band v target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQW42s2fG4L8"
      },
      "outputs": [],
      "source": [
        "age_band = studentInfo.groupby(['age_band', 'final_result']).agg(count=('Index','count')).reset_index()\n",
        "age_band = age_band.sort_values(['final_result', 'age_band'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v_ACvPoG59u"
      },
      "outputs": [],
      "source": [
        "grouped = age_band.groupby(['final_result'])['count'].transform('sum')\n",
        "\n",
        "# divide the count values in the original dataframe by the corresponding group sum\n",
        "age_band['count_normalized'] = age_band['count'] / grouped\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_KAm7nAT_fS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create some data for the plots\n",
        "x = ['Pass', 'Fail', 'Distinction', 'Withdrawn']\n",
        "y1 = age_band.loc[age_band['age_band'] == '0-35', 'count_normalized'].tolist()\n",
        "y2 = age_band.loc[age_band['age_band'] == '35-55', 'count_normalized'].tolist()\n",
        "y3 = age_band.loc[age_band['age_band'] == '55<=', 'count_normalized'].tolist()\n",
        "\n",
        "#x = age_band['age_band'].unique.tolist()\n",
        "\n",
        "#normalising with total population count for that gender\n",
        "#y1 = [i / 17875*100 for i in y1]\n",
        "#y2 = [i/14718*100 for i in y2]\n",
        "\n",
        "X_axis = np.arange(len(x))\n",
        "\n",
        "plt.bar(X_axis - 0.2, y1, 0.4, label = '0-35')\n",
        "plt.bar(X_axis + 0.2, y2, 0.4, label = '35-55')\n",
        "plt.bar(X_axis + 0.2, y3, 0.4, label = '55<=')\n",
        "\n",
        "\n",
        "plt.xticks(X_axis, x)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"ratio of people\")\n",
        "plt.title(\"Gender v proportion\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFEco-wqWVxQ"
      },
      "source": [
        "*  Can be used as feature but will reserve till the correlation matrix is made\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hsg0UovrCxK"
      },
      "source": [
        "* Checked for highest_education as well. Can definitely be used as a feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j_UeVjSynIO"
      },
      "source": [
        "# Sum_clicks v target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNj7rYoZsXGE"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(studentInfo, studentVle, on='id_student')\n",
        "merged_df['id_student'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckVmY2hWA5Ur"
      },
      "outputs": [],
      "source": [
        "merged_df[merged_df['id_student'] == 537811]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q07cE_OyvJQh"
      },
      "outputs": [],
      "source": [
        "# create a scatter plot\n",
        "plt.scatter(merged_df['final_result'], merged_df['sum_click'])\n",
        "\n",
        "# set the x-axis label\n",
        "plt.xlabel('result')\n",
        "\n",
        "# set the y-axis label\n",
        "plt.ylabel('clicks')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_PzdOu9yWNM"
      },
      "source": [
        "* clearly, theres a downward trend. can be used as a feature even though this was not the best way of checking for trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXtX6Rdvw8YX"
      },
      "outputs": [],
      "source": [
        "# create a scatter plot\n",
        "plt.scatter(merged_df['final_result'], merged_df['date'])\n",
        "\n",
        "# set the x-axis label\n",
        "plt.xlabel('result')\n",
        "\n",
        "# set the y-axis label\n",
        "plt.ylabel('date')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNwDaN6BDwDF"
      },
      "source": [
        "* Tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAveRzwZ5S6h"
      },
      "source": [
        "### Code_module v target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xnnOXVB5wNP"
      },
      "outputs": [],
      "source": [
        "code_module = studentInfo.groupby(['code_module', 'final_result']).agg(count=('Index','count')).reset_index()\n",
        "code_module = code_module.sort_values(['final_result', 'code_module'])\n",
        "code_module_scaled = code_module.sort_values('code_module')\n",
        "\n",
        "code_module_scaled.iloc[0:4, 2] = code_module_scaled.iloc[0:4, 2] / 748*100\n",
        "code_module_scaled.iloc[4:8, 2] = code_module_scaled.iloc[4:8, 2] / 7909*100\n",
        "code_module_scaled.iloc[8:12, 2] = code_module_scaled.iloc[8:12, 2] / 4434*100\n",
        "code_module_scaled.iloc[12:16, 2] = code_module_scaled.iloc[12:16, 2] / 6272*100\n",
        "code_module_scaled.iloc[16:20, 2] = code_module_scaled.iloc[16:20, 2] / 2934*100\n",
        "code_module_scaled.iloc[20:24, 2] = code_module_scaled.iloc[20:24, 2] / 7762*100\n",
        "code_module_scaled.iloc[24:28, 2] = code_module_scaled.iloc[24:28, 2] / 2534*100\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ1dbJQB8HbJ"
      },
      "outputs": [],
      "source": [
        "code_module_scaled.sort_values('count').sort_values('code_module')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIfbFILQEMz2"
      },
      "source": [
        "* 65% of students who studied module AAA passed\n",
        "* 38% of students who studied module BBB passed and 30% withdrew\n",
        "* 44% of students who studied module CCC withdrew\n",
        "* 35% of students who studied module DDD passed and 35% withdrew\n",
        "* 44% of students who studied module EEE passed\n",
        "* 38% of students who studied module FFF passed\n",
        "* 44% of students who studied module GGG passed\n",
        "---\n",
        "* Can be used as a feature but will have to check if model performs better without it cause of other factors because of which, even a correlation matrix won't give insightful inferences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UhIlBbQiEl"
      },
      "source": [
        "# Baseline Model (iteration 1)\n",
        "## For our baseline model, we use Decision tree(high dimensional data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32C6HNMPR7vx"
      },
      "outputs": [],
      "source": [
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50XrUB-PR7nt"
      },
      "outputs": [],
      "source": [
        "#performing label encoding\n",
        "\n",
        "merged_df['gender_num'], _ = pd.factorize(merged_df['gender'])\n",
        "merged_df['code_module_x_num'], _ = pd.factorize(merged_df['code_module_x'])\n",
        "merged_df['code_presentation_x_num'], _ = pd.factorize(merged_df['code_presentation_x'])\n",
        "merged_df['region_num'], _ = pd.factorize(merged_df['region'])\n",
        "merged_df['highest_education_num'], _ = pd.factorize(merged_df['highest_education'])\n",
        "merged_df['imd_band_num'], _ = pd.factorize(merged_df['imd_band'])\n",
        "merged_df['age_band_num'], _ = pd.factorize(merged_df['age_band'])\n",
        "merged_df['disability_num'], _ = pd.factorize(merged_df['disability'])\n",
        "merged_df['num_click'], _ = pd.factorize(merged_df['sum_click'])\n",
        "\n",
        "new_df = merged_df[['gender_num', 'code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits','final_result', 'sum_click']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUxC_XWdzn7G"
      },
      "source": [
        "* features - gender, code_module, code_presentation, region, highest_education, imd_band, age_band, disability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cU3EOwnDD5K"
      },
      "outputs": [],
      "source": [
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUbGRm7VdEWH"
      },
      "outputs": [],
      "source": [
        "#plotting the correlation matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "corr = new_df.corr()\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "sns.heatmap(corr, annot=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRyx7XCJdOuQ"
      },
      "source": [
        "* As none of the features are closely correlated to each other, we move forward with all these features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRnU7P4FeZG_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(new_df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CaEGbjxehOk"
      },
      "outputs": [],
      "source": [
        "target_col = 'final_result'\n",
        "feature_cols = ['gender_num', 'code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits', 'sum_click']\n",
        "X = new_df[feature_cols]\n",
        "y = new_df[target_col]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHGkiW6wX0vC"
      },
      "outputs": [],
      "source": [
        "feature_cols = ['code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits', 'gender_x']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3bWB87m37o0"
      },
      "source": [
        "* checking for overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HWOI82o2pRz"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import KFold, cross_val_score\n",
        "#num_folds = 5\n",
        "\n",
        "#kf = KFold(n_splits=num_folds)\n",
        "\n",
        "# Define the model\n",
        "#model = DecisionTreeClassifier()\n",
        "\n",
        "# Perform cross-validation\n",
        "#scores = cross_val_score(model, X, y, cv=kf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEkA8jC_22W_"
      },
      "outputs": [],
      "source": [
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsrK-pMX3-Q7"
      },
      "source": [
        "* probably is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj88LDyQreXy"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18wJ3_PwFjxx"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "#iris = load_iris()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier object\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_test = y_test.astype('category')\n",
        "y_test_encoded = y_test.cat.codes\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = pd.Series(clf.predict(X_test))\n",
        "\n",
        "y_pred = y_pred.astype('category')\n",
        "y_pred_encoded = y_pred.cat.codes\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y00X_j7BMqn4"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7RHf9c9KNzz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define true and predicted labels\n",
        "#y_true = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
        "#y_pred = [0, 0, 2, 0, 1, 1, 0, 1, 2]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Normalize confusion matrix\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Define class names\n",
        "class_names = ['Withdrawn', 'Distinction', 'Pass', 'Fail']\n",
        "\n",
        "# Plot confusion matrix as heatmap for each class\n",
        "#for i, class_name in enumerate(class_names):\n",
        "plt.figure()\n",
        "sns.heatmap(cm_norm, annot=True, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(f'Confusion matrix for {class_names}')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUn6ON2VND_H"
      },
      "source": [
        "* Most misclassified instances are that of the class 'Distinction'\n",
        "* Order(highest to lowest) of True Positives is in the same order(highest to lowest) of number of instances of classes\n",
        "* This can be accredited to the skewness of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xix1z4QJg_CI"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#define the parameter grid to search\n",
        "#param_grid = {'max_depth': [2, 4, 6, 8, 10],\n",
        "#             'min_samples_split': [2, 5, 10, 15, 20]}\n",
        "\n",
        "# perform a grid search using cross-validation\n",
        "#grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "\n",
        "# fit the grid search to the training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "#print the best parameters and the corresponding score\n",
        "#print('Best parameters:', grid_search.best_params_)\n",
        "#print('Best score:', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zgNg3tLdVCh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IPqqKMTOO3H"
      },
      "source": [
        "### Backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0QcVvfoOO3R"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'column' is the categorical variable column name\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEdqscZ5OO3R"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
        "#X = pd.DataFrame(X)  # Convert X to a DataFrame if it's not already\n",
        "\n",
        "# Add a column of ones to represent the intercept term\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the initial model with all features\n",
        "model = sm.OLS(y.astype(float), X).fit()\n",
        "\n",
        "# Perform backward elimination\n",
        "while len(X.columns) > 1:  # Stop when only the intercept term is left\n",
        "    # Get the p-values for each feature\n",
        "    p_values = model.pvalues[1:]  # Exclude the intercept term p-value\n",
        "\n",
        "    # Identify the feature with the highest p-value\n",
        "    feature_to_remove = p_values.idxmax()\n",
        "\n",
        "    if p_values[feature_to_remove] > 0.05:  # Set your significance level (e.g., 0.05)\n",
        "        # Remove the feature with the highest p-value\n",
        "        X = X.drop(columns=feature_to_remove)\n",
        "        \n",
        "        # Fit the updated model\n",
        "        model = sm.OLS(y, X).fit()\n",
        "    else:\n",
        "        break  # Stop if no features have p-value above the significance level\n",
        "\n",
        "# Get the final model summary\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqSfW8i4OSeb"
      },
      "source": [
        "* P values (P>|t|) of every feature is less than the threshold of 0.05 meaning the corresponding features have a significant impact on the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeHYuIsFn9cx"
      },
      "source": [
        "### Implementing Naive Bayes on the same feature set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyQvmzvVn9cx"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "model.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZfMol08n9cy"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgzQA8Bzn9cy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "y_pred_1 = model.predict(X_test)\n",
        "\n",
        "accuray = accuracy_score(y_pred_1, y_test)\n",
        "f1 = f1_score(y_pred_1, y_test, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy:\", accuray)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test, y_pred_1))"
      ],
      "metadata": {
        "id": "hnWmmWsnoWaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao8NuvpGWLWa"
      },
      "source": [
        "#2nd iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzwrti12uQ95"
      },
      "outputs": [],
      "source": [
        "studentInfo['id_student'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJiZXQYDvuXl"
      },
      "source": [
        "* number of courses registered with is not correlated with the end result/target variable. Eg. - a student registered for 5 different courses, be it different times(semesters) does not guarantee if he/she is an overachiever or just the fact that person re-registered becuase of failure to complete said module on multiple attempts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wznZH9HIWfhb"
      },
      "outputs": [],
      "source": [
        "df_sumClick = merged_df[['sum_click']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZPtxufuY-2D"
      },
      "outputs": [],
      "source": [
        "df_sumClick['sum_click'], _ = pd.factorize(df_sumClick['sum_click'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5aXIEWaZAHb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df_sumClick, test_df_sumClick = train_test_split(df_sumClick, test_size=0.2, random_state=42)\n",
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0X68a8sZP-f"
      },
      "outputs": [],
      "source": [
        "target_col = 'final_result'\n",
        "feature_cols = ['sum_click']\n",
        "X = merged_df[feature_cols]\n",
        "y = merged_df[target_col]\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxEugcyurz0H"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHqOkj-bZTMA"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "#iris = load_iris()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier object\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train_2, y_train_2)\n",
        "\n",
        "y_test_2 = y_test.astype('category')\n",
        "y_test_encoded_2 = y_test_2.cat.codes\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_2 = pd.Series(clf.predict(X_test_2))\n",
        "\n",
        "y_pred_2 = y_pred_2.astype('category')\n",
        "y_pred_encoded_2 = y_pred_2.cat.codes\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test_encoded_2, y_pred_encoded_2)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test_2, y_pred_2))"
      ],
      "metadata": {
        "id": "jNfRjEVTvHEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k58VSp9cvKi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5T0GLoYmy7W"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42uHD9W8m1L8"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "model.fit(X_train_2, y_train_2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4rvAchtm1L8"
      },
      "outputs": [],
      "source": [
        "print(X_train_2.shape)\n",
        "print(y_train_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv91_Xhmm1L9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "y_pred_2 = model.predict(X_test_2)\n",
        "\n",
        "accuray = accuracy_score(y_pred_2, y_test_2)\n",
        "f1 = f1_score(y_pred_2, y_test_2, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy:\", accuray)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test_2, y_pred_2))"
      ],
      "metadata": {
        "id": "kjjuzgD7p6as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward Elimination"
      ],
      "metadata": {
        "id": "5-2MpQRcp9Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'column' is the categorical variable column name\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n"
      ],
      "metadata": {
        "id": "WFJ5fSa2p_Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
        "#X = pd.DataFrame(X)  # Convert X to a DataFrame if it's not already\n",
        "\n",
        "# Add a column of ones to represent the intercept term\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the initial model with all features\n",
        "model = sm.OLS(y.astype(float), X).fit()\n",
        "\n",
        "# Perform backward elimination\n",
        "while len(X.columns) > 1:  # Stop when only the intercept term is left\n",
        "    # Get the p-values for each feature\n",
        "    p_values = model.pvalues[1:]  # Exclude the intercept term p-value\n",
        "\n",
        "    # Identify the feature with the highest p-value\n",
        "    feature_to_remove = p_values.idxmax()\n",
        "\n",
        "    if p_values[feature_to_remove] > 0.05:  # Set your significance level (e.g., 0.05)\n",
        "        # Remove the feature with the highest p-value\n",
        "        X = X.drop(columns=feature_to_remove)\n",
        "        \n",
        "        # Fit the updated model\n",
        "        model = sm.OLS(y, X).fit()\n",
        "    else:\n",
        "        break  # Stop if no features have p-value above the significance level\n",
        "\n",
        "# Get the final model summary\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "ImXHW9LxqD5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_WHXcbWL7J-"
      },
      "source": [
        "# 3rd iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_04Fs3QL9Om"
      },
      "outputs": [],
      "source": [
        "merged_df_3 = pd.merge(studentInfo, studentRegistration, on='id_student')\n",
        "merged_df_3 = pd.merge(merged_df_3, studentVle, on='id_student')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiwShmrXNSmu"
      },
      "outputs": [],
      "source": [
        "merged_df_3 = merged_df_3.dropna(subset=['date_unregistration'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kThRF7rRMpyO"
      },
      "outputs": [],
      "source": [
        "#merged_df_3['gender_num'], _ = pd.factorize(merged_df_3['gender'])\n",
        "merged_df_3['code_module_x_num'], _ = pd.factorize(merged_df_3['code_module_x'])\n",
        "merged_df_3['code_presentation_x_num'], _ = pd.factorize(merged_df_3['code_presentation_x'])\n",
        "merged_df_3['region_num'], _ = pd.factorize(merged_df_3['region'])\n",
        "merged_df_3['highest_education_num'], _ = pd.factorize(merged_df_3['highest_education'])\n",
        "merged_df_3['imd_band_num'], _ = pd.factorize(merged_df_3['imd_band'])\n",
        "merged_df_3['age_band_num'], _ = pd.factorize(merged_df_3['age_band'])\n",
        "merged_df_3['disability_num'], _ = pd.factorize(merged_df_3['disability'])\n",
        "merged_df_3['sum_click'], _ = pd.factorize(merged_df_3['sum_click'])\n",
        "merged_df_3['gender_x'], _ = pd.factorize(merged_df_3['gender'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwPPzI6MMLyu"
      },
      "outputs": [],
      "source": [
        "new_df_3 = merged_df_3[['code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits','final_result', 'gender_x', 'date_registration', 'date_unregistration', 'sum_click']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKgUWjxkhDxz"
      },
      "outputs": [],
      "source": [
        "new_df_3 = new_df_3.dropna(subset=['date_registration'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npa7VF0nfJ8H"
      },
      "outputs": [],
      "source": [
        "new_df_3.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqYo5cwvNl_o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df_3, test_df_3 = train_test_split(new_df_3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUNRiXrgNzSZ"
      },
      "outputs": [],
      "source": [
        "target_col = 'final_result'\n",
        "feature_cols = ['code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits', 'gender_x', 'date_registration','date_unregistration', 'sum_click']\n",
        "X_3 = new_df_3[feature_cols]\n",
        "y_3 = new_df_3[target_col]\n",
        "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-g4LBBtsDK3"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isYMGC6jOCyP"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1rUGS-fYGJ7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpmviFM4OLDF"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "#iris = load_iris()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier object\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train_3, y_train_3)\n",
        "\n",
        "y_test_3 = y_test_3.astype('category')\n",
        "y_test_encoded_3 = y_test_3.cat.codes\n",
        "y_train_3 = y_train_3.astype('category')\n",
        "y_train_encoded_3 = y_train_3.cat.codes\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_3 = pd.Series(clf.predict(X_test_3))\n",
        "y_train_pred_3 = pd.Series(clf.predict(X_train_3))\n",
        "\n",
        "y_pred_3 = y_pred_3.astype('category')\n",
        "y_train_pred_3 = y_train_pred_3.astype('category')\n",
        "\n",
        "y_pred_encoded_3 = y_pred_3.cat.codes\n",
        "y_train_pred_encoded_3 = y_train_pred_3.cat.codes\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test_encoded_3, y_pred_encoded_3)\n",
        "accuracy_train = accuracy_score(y_train_encoded_3, y_train_pred_encoded_3)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"train accuracy\", accuracy_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIeEk1CO0BBk"
      },
      "source": [
        "* both train and test accuracy are coming out to be close to 1. This could indicate that the model is not complex enough to capture the underlying patterns and relationships in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9b3abIXvBrm"
      },
      "outputs": [],
      "source": [
        "print(y_train_3.shape)\n",
        "print(y_pred_encoded_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FH6NJKzZ4eP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test_3, y_pred_3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKrb5L42Ynx5"
      },
      "source": [
        "* selected features favours prediction of \"Withdrawn\" class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymf70aFoYAcx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define true and predicted labels\n",
        "#y_true = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
        "#y_pred = [0, 0, 2, 0, 1, 1, 0, 1, 2]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test_3, y_pred_3)\n",
        "\n",
        "# Normalize confusion matrix\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Define class names\n",
        "class_names = ['Withdrawn', 'Distinction', 'Pass', 'Fail']\n",
        "\n",
        "# Plot confusion matrix as heatmap for each class\n",
        "#for i, class_name in enumerate(class_names):\n",
        "plt.figure()\n",
        "sns.heatmap(cm_norm, annot=True, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(f'Confusion matrix for {class_names}')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqkyRN6XYMab"
      },
      "outputs": [],
      "source": [
        "#plotting the correlation matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "corr = new_df_3.corr()\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "sns.heatmap(corr, annot=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMvL_lBsQvDP"
      },
      "source": [
        "### Backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkmGs5PZQvDQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'column' is the categorical variable column name\n",
        "label_encoder = LabelEncoder()\n",
        "y_3 = label_encoder.fit_transform(y_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekMTh4EJZpfw"
      },
      "outputs": [],
      "source": [
        "print(y_3.shape)\n",
        "print(X_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7OyjGqpQvDQ"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
        "#X = pd.DataFrame(X)  # Convert X to a DataFrame if it's not already\n",
        "\n",
        "# Add a column of ones to represent the intercept term\n",
        "X_3 = sm.add_constant(X_3)\n",
        "\n",
        "# Fit the initial model with all features\n",
        "model = sm.OLS(y_3.astype(float), X_3).fit()\n",
        "\n",
        "# Perform backward elimination\n",
        "while len(X_3.columns) > 1:  # Stop when only the intercept term is left\n",
        "    # Get the p-values for each feature\n",
        "    p_values = model.pvalues[1:]  # Exclude the intercept term p-value\n",
        "\n",
        "    # Identify the feature with the highest p-value\n",
        "    feature_to_remove = p_values.idxmax()\n",
        "\n",
        "    if p_values[feature_to_remove] > 0.05:  # Set your significance level (e.g., 0.05)\n",
        "        # Remove the feature with the highest p-value\n",
        "        X_3 = X_3.drop(columns=feature_to_remove)\n",
        "        \n",
        "        # Fit the updated model\n",
        "        model = sm.OLS(y_3, X_3).fit()\n",
        "    else:\n",
        "        break  # Stop if no features have p-value above the significance level\n",
        "\n",
        "# Get the final model summary\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIcqJ8raQvDQ"
      },
      "source": [
        "* P values (P>|t|) of every feature is less than the threshold of 0.05 meaning the corresponding features have a significant impact on the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing cross-validation to check for overfitting"
      ],
      "metadata": {
        "id": "VkFgGEyZwhCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UeCaxvZaWDz"
      },
      "outputs": [],
      "source": [
        "#cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_3, y_3, cv=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ZHreanfwY7"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9f87z3pfxgk"
      },
      "source": [
        "* The model does not perform well on the cross validation set confirming that it is overfitting the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to4KZ2Lg3i9i"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmY_cm3N_YYy"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "model.fit(X_train_3, y_train_3);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7Y5nTb15bsl"
      },
      "outputs": [],
      "source": [
        "print(X_train_3.shape)\n",
        "print(y_train_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXSMB_luh-Ba"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "y_pred_3 = model.predict(X_test_3)\n",
        "\n",
        "accuray = accuracy_score(y_pred_3, y_test_3)\n",
        "f1 = f1_score(y_pred_3, y_test_3, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy:\", accuray)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0SUktuMvMld"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3PUiPRavMld"
      },
      "outputs": [],
      "source": [
        "studentInfo['id_student'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9duQvnyvMle"
      },
      "source": [
        "* number of courses registered with is not correlated with the end result/target variable. Eg. - a student registered for 5 different courses, be it different times(semesters) does not guarantee if he/she is an overachiever or just the fact that person re-registered becuase of failure to complete said module on multiple attempts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test_3, y_pred_3))"
      ],
      "metadata": {
        "id": "n5YfMe5ww68M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WO38MKOaw5Oa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAIM_8o-x6ps"
      },
      "source": [
        "# 4th iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k39IcufDyM3x"
      },
      "outputs": [],
      "source": [
        "merged_df_4 = pd.merge(studentInfo, studentAssessment, on='id_student', how='outer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gHB27rByM3x"
      },
      "outputs": [],
      "source": [
        "#performing label encoding\n",
        "\n",
        "merged_df_4['gender_num'], _ = pd.factorize(merged_df_4['gender'])\n",
        "merged_df_4['code_module_x_num'], _ = pd.factorize(merged_df_4['code_module'])\n",
        "merged_df_4['code_presentation_x_num'], _ = pd.factorize(merged_df_4['code_presentation'])\n",
        "merged_df_4['region_num'], _ = pd.factorize(merged_df_4['region'])\n",
        "merged_df_4['highest_education_num'], _ = pd.factorize(merged_df_4['highest_education'])\n",
        "merged_df_4['imd_band_num'], _ = pd.factorize(merged_df_4['imd_band'])\n",
        "merged_df_4['age_band_num'], _ = pd.factorize(merged_df_4['age_band'])\n",
        "merged_df_4['disability_num'], _ = pd.factorize(merged_df_4['disability'])\n",
        "#merged_df_4['date_submitted_num'], _ = pd.factorize(merged_df_4['sum_click'])\n",
        "#merged_df_4['date_submitted_num'], _ = pd.factorize(merged_df_4['sum_click'])\n",
        "\n",
        "new_df_4 = merged_df_4[['gender_num', 'code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits','final_result', 'date_submitted', 'score']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4y2SRVYyM3x"
      },
      "source": [
        "* features - gender, code_module, code_presentation, region, highest_education, imd_band, age_band, disability"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df_4 = new_df_4.dropna(subset=['date_submitted'])\n",
        "new_df_4 = new_df_4.dropna(subset=['score'])\n",
        "\n",
        "\n",
        "print(new_df_4.isnull().sum())\n"
      ],
      "metadata": {
        "id": "6zrZf0Zn0v2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZtnh6_AyM3y"
      },
      "outputs": [],
      "source": [
        "#plotting the correlation matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "corr = new_df_4.corr()\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "sns.heatmap(corr, annot=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyxIAjLdyM3y"
      },
      "source": [
        "* As none of the features are closely correlated to each other, we move forward with all these features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQvLhWrKyM3y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(new_df_4, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOAxRkH5yM3z"
      },
      "outputs": [],
      "source": [
        "target_col = 'final_result'\n",
        "feature_cols = ['gender_num', 'code_module_x_num','code_presentation_x_num','region_num','highest_education_num','imd_band_num','age_band_num','disability_num','num_of_prev_attempts','studied_credits', 'date_submitted', 'score']\n",
        "X_4 = new_df_4[feature_cols]\n",
        "y_4 = new_df_4[target_col]\n",
        "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4, y_4, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuaxjzhlyM3z"
      },
      "source": [
        "* checking for overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xcChBmZyM30"
      },
      "outputs": [],
      "source": [
        "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt7Rua7gyM30"
      },
      "source": [
        "* probably is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3nJDZ-qyM30"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HQYKuPsyM30"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "#iris = load_iris()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier object\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train_4, y_train_4)\n",
        "\n",
        "y_test_4 = y_test_4.astype('category')\n",
        "y_test_encoded_4 = y_test_4.cat.codes\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_4 = pd.Series(clf.predict(X_test_4))\n",
        "\n",
        "y_pred_4 = y_pred_4.astype('category')\n",
        "y_pred_encoded_4 = y_pred_4.cat.codes\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test_encoded_4, y_pred_encoded_4)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7lc1uLqyM31"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define true and predicted labels\n",
        "#y_true = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
        "#y_pred = [0, 0, 2, 0, 1, 1, 0, 1, 2]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test_4, y_pred_4)\n",
        "\n",
        "# Normalize confusion matrix\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Define class names\n",
        "class_names = ['Withdrawn', 'Distinction', 'Pass', 'Fail']\n",
        "\n",
        "# Plot confusion matrix as heatmap for each class\n",
        "#for i, class_name in enumerate(class_names):\n",
        "plt.figure()\n",
        "sns.heatmap(cm_norm, annot=True, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(f'Confusion matrix for {class_names}')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BR8WhYKyM31"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#define the parameter grid to search\n",
        "#param_grid = {'max_depth': [2, 4, 6, 8, 10],\n",
        "#             'min_samples_split': [2, 5, 10, 15, 20]}\n",
        "\n",
        "# perform a grid search using cross-validation\n",
        "#grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "\n",
        "# fit the grid search to the training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "#print the best parameters and the corresponding score\n",
        "#print('Best parameters:', grid_search.best_params_)\n",
        "#print('Best score:', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGXslVRFyM32"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test_4, y_pred_4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edxCTJvNyM32"
      },
      "source": [
        "### Backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fCp6puByM32"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'column' is the categorical variable column name\n",
        "label_encoder = LabelEncoder()\n",
        "y_4 = label_encoder.fit_transform(y_4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw4ey00JyM33"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
        "#X = pd.DataFrame(X)  # Convert X to a DataFrame if it's not already\n",
        "\n",
        "# Add a column of ones to represent the intercept term\n",
        "X_4 = sm.add_constant(X_4)\n",
        "\n",
        "# Fit the initial model with all features\n",
        "model = sm.OLS(y_4.astype(float), X_4).fit()\n",
        "\n",
        "# Perform backward elimination\n",
        "while len(X_4.columns) > 1:  # Stop when only the intercept term is left\n",
        "    # Get the p-values for each feature\n",
        "    p_values = model.pvalues[1:]  # Exclude the intercept term p-value\n",
        "\n",
        "    # Identify the feature with the highest p-value\n",
        "    feature_to_remove = p_values.idxmax()\n",
        "\n",
        "    if p_values[feature_to_remove] > 0.05:  # Set your significance level (e.g., 0.05)\n",
        "        # Remove the feature with the highest p-value\n",
        "        X_4 = X_4.drop(columns=feature_to_remove)\n",
        "        \n",
        "        # Fit the updated model\n",
        "        model = sm.OLS(y_4, X_4).fit()\n",
        "    else:\n",
        "        break  # Stop if no features have p-value above the significance level\n",
        "\n",
        "# Get the final model summary\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiz3IgZHyM33"
      },
      "source": [
        "* 'coef' values of date_submitted and score is minimal and can be discarded as a feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRR80DufyM33"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlrFXkUTyM34"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "model.fit(X_train_4, y_train_4);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB6LG9IDyM34"
      },
      "outputs": [],
      "source": [
        "print(X_train_4.shape)\n",
        "print(y_train_4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnerCXRJyM34"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "y_pred_4 = model.predict(X_test_4)\n",
        "\n",
        "accuray = accuracy_score(y_pred_4, y_test_4)\n",
        "f1 = f1_score(y_pred_4, y_test_4, average=\"weighted\")\n",
        "\n",
        "print(\"Accuracy:\", accuray)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report\n",
        "print(classification_report(y_test_4, y_pred_4))"
      ],
      "metadata": {
        "id": "n2hCmDbG1ZQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN(Artificial Neural Network)\n",
        "* We use the same feature set as the one used in the baseline model(i.e iteration 1)"
      ],
      "metadata": {
        "id": "6A71hDl7D2S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install bayesian-optimization==1.4.1"
      ],
      "metadata": {
        "id": "fiKs9PIYF0ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "dcXviE8OF2vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to the Series\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n"
      ],
      "metadata": {
        "id": "w777HGDDD8dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Create a simple dataset for demonstration\n",
        "# Input features (X) and corresponding labels (y)\n",
        "#X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "#y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a dense (fully connected) layer with 8 units and 'relu' activation\n",
        "model.add(Dense(8, input_dim=11, activation='relu'))\n",
        "\n",
        "# Add another dense layer with 4 units and 'relu' activation\n",
        "model.add(Dense(4, activation='relu'))\n",
        "\n",
        "# Add an output layer with 1 unit and 'sigmoid' activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train, y_train_encoded, epochs=1000, batch_size=4)\n",
        "#implementing early stopping\n",
        "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train_encoded, epochs = 1000, validation_split = 0.2,shuffle = True, verbose = 0, \n",
        "                callbacks = [earlystopper])\n",
        "#history_dict=history.history\n",
        "# Predict on new data\n",
        "#new_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "#predictions = model.predict(new_data)\n",
        "\n",
        "#print(predictions)\n"
      ],
      "metadata": {
        "id": "z7FrURA2I9N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "import keras\n",
        "from keras.optimizers import *\n",
        "from keras.initializers import *\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import chain"
      ],
      "metadata": {
        "id": "EcsxeR1AXc57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, input_dim=11, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(64, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(128, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(Dense(512, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(1024, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(512, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(Dense(512, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(1024, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(512, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(Dense(128, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(64, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Dense(32, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"SGD\", loss='binary_crossentropy', metrics=[\"binary_accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Instantiate 'EarlyStopping' function\n",
        "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "# Fits model over 1000 iterations with 'earlystopper' callback, and assigns it to history\n",
        "#history = model.fit(X_train, y_train, epochs = 1000, validation_split = 0.2,shuffle = True, verbose = 0, \n",
        "                callbacks = [earlystopper])"
      ],
      "metadata": {
        "id": "iLmDuNs684rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = model.fit(X_train, y_train_encoded, batch_size=1000, epochs=200, validation_split=0.2, shuffle=True, verbose=,callbacks = [earlystopper])"
      ],
      "metadata": {
        "id": "O1BBp9JzXC7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "m9A1ZcoGX-dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#hello"
      ],
      "metadata": {
        "id": "P4Advh7TmdYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Generate some dummy data\n",
        "#data = np.random.random((1000, 100))\n",
        "#labels = np.random.randint(2, size=(1000, 1))\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(Dense(64, activation='relu', input_dim=11))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#early stopper\n",
        "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=1000, batch_size=32, callbacks = [earlystopper])\n",
        "\n",
        "# Make predictions\n",
        "#predictions = model.predict(data)\n"
      ],
      "metadata": {
        "id": "X4CQyP_ZYGiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fdbf202-ef85-4710-de34-0cf43f03a3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "325163/325165 [============================>.] - ETA: 0s - loss: -584933769216.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 912s 3ms/step - loss: -584941240320.0000 - accuracy: 0.1224\n",
            "Epoch 2/1000\n",
            "325153/325165 [============================>.] - ETA: 0s - loss: -8322516254720.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 912s 3ms/step - loss: -8322888499200.0000 - accuracy: 0.1224\n",
            "Epoch 3/1000\n",
            "325150/325165 [============================>.] - ETA: 0s - loss: -35348629422080.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 912s 3ms/step - loss: -35349740912640.0000 - accuracy: 0.1224\n",
            "Epoch 4/1000\n",
            "325152/325165 [============================>.] - ETA: 0s - loss: -94177375289344.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 904s 3ms/step - loss: -94179245948928.0000 - accuracy: 0.1224\n",
            "Epoch 5/1000\n",
            "325151/325165 [============================>.] - ETA: 0s - loss: -197493132361728.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 903s 3ms/step - loss: -197496068374528.0000 - accuracy: 0.1224\n",
            "Epoch 6/1000\n",
            "325154/325165 [============================>.] - ETA: 0s - loss: -357658569736192.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 907s 3ms/step - loss: -357660113240064.0000 - accuracy: 0.1224\n",
            "Epoch 7/1000\n",
            "325158/325165 [============================>.] - ETA: 0s - loss: -587510321250304.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 901s 3ms/step - loss: -587515085979648.0000 - accuracy: 0.1224\n",
            "Epoch 8/1000\n",
            "325149/325165 [============================>.] - ETA: 0s - loss: -901587186745344.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 898s 3ms/step - loss: -901597185966080.0000 - accuracy: 0.1224\n",
            "Epoch 9/1000\n",
            "325156/325165 [============================>.] - ETA: 0s - loss: -1312029293936640.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 896s 3ms/step - loss: -1312035602169856.0000 - accuracy: 0.1224\n",
            "Epoch 10/1000\n",
            "325153/325165 [============================>.] - ETA: 0s - loss: -1831398482640896.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325165/325165 [==============================] - 890s 3ms/step - loss: -1831396737810432.0000 - accuracy: 0.1224\n",
            "Epoch 11/1000\n",
            "325161/325165 [============================>.] - ETA: 0s - loss: -2472141299646464.0000 - accuracy: 0.1224"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325165/325165 [==============================] - 892s 3ms/step - loss: -2472146399920128.0000 - accuracy: 0.1224\n",
            "Epoch 12/1000\n",
            "229396/325165 [====================>.........] - ETA: 4:22 - loss: -3121890394636288.0000 - accuracy: 0.1224"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V24PZniMmod3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "34Fl34QO4Uwk",
        "rUj4AyLP2OOT",
        "5j_UeVjSynIO",
        "F6UhIlBbQiEl",
        "ao8NuvpGWLWa",
        "5-2MpQRcp9Pr",
        "S_WHXcbWL7J-",
        "wAIM_8o-x6ps"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}